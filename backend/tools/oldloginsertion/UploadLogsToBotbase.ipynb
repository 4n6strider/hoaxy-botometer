{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to import log:  botornot.log201506\n",
      "Finished importing log:  botornot.log201506\n",
      "921.1845338344574 seconds elapsed\n",
      "Log Import Process Completed!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/evn python\n",
    "\n",
    "#Author: Mihai Avram, e-mail: mihai.v.avram@gmail.com\n",
    "\n",
    "#ALL IMPORTS\n",
    "#for parsing the data in the logs\n",
    "import json\n",
    "#for connecting to the database\n",
    "import psycopg2\n",
    "#for error logging\n",
    "import sys\n",
    "#for timing purposes\n",
    "import time\n",
    "\n",
    "#ALL FUNCTIONS\n",
    "#function for deciding on a score value to use for bot_score_english and bot_score_universal depending on what's available in the log\n",
    "def score_decider(potential_score_keys, line_json):\n",
    "    for key in potential_score_keys:\n",
    "        if len(key) == 1:\n",
    "            key1 = key[0]\n",
    "            try:\n",
    "                score = line_json[key1]\n",
    "                return score\n",
    "            except:\n",
    "                continue\n",
    "        elif len(key) == 2:\n",
    "            key1 = key[0]\n",
    "            key2 = key[1]\n",
    "            try:\n",
    "                score = line_json[key1][key2]\n",
    "                return score\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "#lookps up previous num_requests value\n",
    "def num_requests_lookup(user_id):\n",
    "    botbase_cursor.execute(\"\"\"SELECT num_requests FROM public.botscore WHERE user_id=%s ORDER BY time_stamp DESC LIMIT 1;\"\"\", (user_id,))\n",
    "    return botbase_cursor.fetchone()\n",
    "\n",
    "#inserts log to database\n",
    "def log_insertion_script(user_id, screen_name, time_stamp, all_bot_scores, bot_score_english, \\\n",
    "                bot_score_universal, requester_ip, tweets_per_day, num_tweets, \\\n",
    "                num_mentions, latest_tweet_timestamp, num_requests, user_profile):\n",
    "    \n",
    "    botbase_cursor.execute(\"\"\"INSERT INTO public.botscore(\n",
    "                user_id, screen_name, time_stamp, all_bot_scores, bot_score_english, \n",
    "                bot_score_universal, requester_ip, tweets_per_day, num_tweets, \n",
    "                num_mentions, latest_tweet_timestamp, num_requests, user_profile) \n",
    "                              VALUES \n",
    "                (%s, %s, to_timestamp(%s), %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\"\"\", \\\n",
    "                (user_id, screen_name, time_stamp, json.dumps(all_bot_scores), bot_score_english, \\\n",
    "                bot_score_universal, requester_ip, tweets_per_day, num_tweets, \\\n",
    "                num_mentions, latest_tweet_timestamp, num_requests, user_profile))\n",
    "\n",
    "    #commiting changes\n",
    "    pgsqlconn.commit()\n",
    "\n",
    "#MAIN CODE\n",
    "if __name__ == '__main__':\n",
    "    #connecting to the database\n",
    "    pgsqlconn = psycopg2.connect(host='localhost', user='postgres', password='password', dbname='botbase')\n",
    "    #cursor needed to execute db operations\n",
    "    botbase_cursor = pgsqlconn.cursor()\n",
    "    #starting timer\n",
    "    timer_start = time.time()\n",
    "    \n",
    "    #log name and location information\n",
    "    log_path = '/home/mavram/Research/HoaxyBotometer/ImportBackuplogsTask/logs/backups/unzipstage/'\n",
    "    #log_path = '/home/mavram/Research/HoaxyBotometer/ImportBackuplogsTask/logs/recent/'\n",
    "    log_file_list = ['botornot.log201506']\n",
    "                    #'botornot.log201506',\n",
    "                     #, 'botornot.log201510', 'botornot.log201605', 'botornot.log201701', \\\n",
    "                     #'botornot.log201702', 'botornot.log201705', 'botornot.log.2017-05-14', 'botornot.log.2017-05-21', \\\n",
    "                     #'botornot.log.2017-05-28', 'botornot.log.2017-06-04', 'botornot.log.2017-06-11', 'botornot.log.2017-06-18', \\\n",
    "                     #'botornot.log.2017-06-25', 'botornot.log.2017-07-02', 'botornot.log.2017-07-09', 'botornot.log.2017-07-16', \\\n",
    "                     #'botornot.log.2017-07-23', 'botornot.log.2017-07-30', 'botornot.log.2017-08-06', 'botornot.log.2017-08-13']\n",
    "                    #recent\n",
    "                    #botornot.log.2017-08-20  botornot.log.2017-08-27\n",
    "    #log to store any errors due to the logs not containing the proper data (i.e. other logging information such as errors or other requests)\n",
    "    error_log_file = open(\"botscoreloginsertion.err\", \"w\")\n",
    "\n",
    "    \n",
    "    #iterating through all log files\n",
    "    for log in log_file_list:\n",
    "        print(\"Starting to import log: \", log)\n",
    "        file_location = log_path + log\n",
    "\n",
    "        #parsing logs and uploading the entries to the botometer database\n",
    "        log_file = open(file_location,\"r\")\n",
    "\n",
    "        for line_num, line in enumerate(log_file):\n",
    "            try: \n",
    "                line_json = json.loads(line)\n",
    "                user_id = line_json[\"search\"][\"user_id\"]\n",
    "                screen_name = line_json[\"search\"][\"sn\"]\n",
    "                time_stamp = line_json[\"timestamp\"]\n",
    "                #some timestamps are stored in milliseconds so for those we divide by 1000\n",
    "                if len(str(time_stamp)) >= 12:\n",
    "                    time_stamp = time_stamp/1000\n",
    "                all_bot_scores = line_json[\"categories\"]\n",
    "                #english bot score which is either found in line_json[\"score\"], line_json[\"classification\"], line_json[\"score\"][\"english\"]\n",
    "                keys = [[\"score\",\"english\"],[\"score\"],[\"classification\"]]\n",
    "                bot_score_english = score_decider(keys, line_json)\n",
    "                #universal bot score which is either found in line_json[\"score\"][\"universal\"] or line_json[\"categories\"][\"languageagnostic_classification\"] otherwise null\n",
    "                keys = [[\"score\",\"universal\"],[\"categories\",\"languageagnostic_classification\"]]\n",
    "                bot_score_universal = score_decider(keys, line_json)\n",
    "                #storing a comma delimited string of ips\n",
    "                requester_ip = line_json[\"remote_ip\"]\n",
    "                #some ips are stored in lists and some not, must distinguish and treat them separately here\n",
    "                #in order to yield <ip1>,<ip2>,etc...\n",
    "                if type(requester_ip) == list:\n",
    "                    requester_ip = ','.join(line_json[\"remote_ip\"])                \n",
    "                tweets_per_day = None\n",
    "                num_tweets = line_json[\"num_tweets\"]\n",
    "                num_mentions = None\n",
    "                latest_tweet_timestamp = None\n",
    "                num_requests = 1\n",
    "                user_profile = None\n",
    "                try:\n",
    "                    #retrieving previous number of requests for user, so that we can increment it by one\n",
    "                    num_requests_new = num_requests_lookup(int(user_id))[0]\n",
    "                    num_requests_new = num_requests_new + 1\n",
    "                except TypeError:\n",
    "                    #user does not exist yet in the database\n",
    "                    num_requests_new = 1\n",
    "                #inserting data to the database\n",
    "                log_insertion_script(user_id, screen_name, time_stamp, all_bot_scores, bot_score_english, bot_score_universal, \\\n",
    "                            str(requester_ip), tweets_per_day, num_tweets, num_mentions, latest_tweet_timestamp, num_requests_new, user_profile)\n",
    "            except:\n",
    "                error_log_file.write(\"File: \" + log + \" LineNumber: \" + str(line_num) + \" Error: \" + str(sys.exc_info()[0]) + \"\\n\")\n",
    "                continue\n",
    "\n",
    "        print(\"Finished importing log: \", log)\n",
    "\n",
    "    #closing access to database\n",
    "    botbase_cursor.close()\n",
    "    pgsqlconn.close()\n",
    "\n",
    "    #closing log files\n",
    "    log_file.close()\n",
    "    error_log_file.close()\n",
    "\n",
    "    #ending and evaluating time elapsed\n",
    "    print(\"%s seconds elapsed\" % (time.time()-timer_start))\n",
    "    print(\"Log Import Process Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
